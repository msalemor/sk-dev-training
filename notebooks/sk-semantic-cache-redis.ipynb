{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Semantic Cache with Redis Cache\n",
    "\n",
    "Learning objectives:\n",
    "\n",
    "- Use Redis Cache to cache LLM responses\n",
    "- Improve performance and save on Token costs\n",
    "\n",
    "## Redis setup\n",
    "\n",
    "### Running Redis in a local container:\n",
    "\n",
    "- docker pull `redis/redis-stack:latest`\n",
    "  - **Note:** this version of redis includes the `RedisSearch` module\n",
    "- Then execute: \n",
    "  - `docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest`\n",
    "\n",
    "Connection string:\n",
    "\n",
    "- `REDIS_CONN_STR=localhost`\n",
    "\n",
    "### Running from Azure Redis Cache Enterprise\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Load required .NET packages and supporting constants, classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: dotenv.net\"\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.47.0\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.AzureOpenAI, 1.47.0\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Plugins.Memory, 1.47.0-alpha\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Redis, 1.47.0-alpha\"\n",
    "#r \"nuget: StackExchange.Redis\"\n",
    "\n",
    "\n",
    "using System;\n",
    "\n",
    "using System.IO;\n",
    "using System.Net.Http;\n",
    "using System.Text;\n",
    "using System.Text.RegularExpressions;\n",
    "using System.Text.Json;\n",
    "using System.Text.Json.Serialization;\n",
    "using StackExchange.Redis;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.AzureOpenAI;\n",
    "using Microsoft.SemanticKernel.Connectors.Redis;\n",
    "using Microsoft.SemanticKernel.Memory;\n",
    "using Microsoft.SemanticKernel.Plugins.Memory;\n",
    "\n",
    "using dotenv.net;\n",
    "using InteractiveKernel = Microsoft.DotNet.Interactive.Kernel;\n",
    "\n",
    "#!import Models/Models.cs\n",
    "\n",
    "const int ADA_EMBEDDING_SIZE = 1536;\n",
    "const string MemoryCollectionName = \"SemanticCache\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the API Key and endpoints from environment variables or the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Load the .env file\n",
    "DotEnv.Load();\n",
    "\n",
    "// Get the OpenAI deployment name, endpoint, and key from the environment variables\n",
    "var deploymentName = Environment.GetEnvironmentVariable(\"GPT_OPENAI_DEPLOYMENT_NAME\");\n",
    "var endpoint = Environment.GetEnvironmentVariable(\"GPT_OPENAI_ENDPOINT\");\n",
    "var apiKey = Environment.GetEnvironmentVariable(\"GPT_OPENAI_KEY\");\n",
    "var redis_conn_str = Environment.GetEnvironmentVariable(\"REDIS_CONN_STR\");\n",
    "var adaDeploymentName = Environment.GetEnvironmentVariable(\"GPT_EMBEDDING_MODEL\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a kernel instance configured for text completions and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// I'm using a RAM stored Vector DB, but I can switch providers like Azure Search, DuckDB, SQLite, etc.\n",
    "#pragma warning disable CS8618,IDE0009,CA1051,CA1050,CA1707,CA2007,VSTHRD111,CS1591,RCS1110,CA5394,SKEXP0001,SKEXP0002,SKEXP0003,SKEXP0004,SKEXP0010,SKEXP0011,SKEXP0012,SKEXP0020,SKEXP0021,SKEXP0022,SKEXP0023,SKEXP0024,SKEXP0025,SKEXP0026,SKEXP0027,SKEXP0028,SKEXP0029,SKEXP0030,SKEXP0031,SKEXP0032,SKEXP0040,SKEXP0041,SKEXP0042,SKEXP0050,SKEXP0051,SKEXP0052,SKEXP0053,SKEXP0054,SKEXP0055,SKEXP0060,SKEXP0061,SKEXP0101,SKEXP0102\n",
    "\n",
    "// Note: Added this because I am having problems with SSL certificate validation\n",
    "var handler = new HttpClientHandler();\n",
    "handler.CheckCertificateRevocationList = false;\n",
    "var httpClient = new HttpClient(handler);\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "    .AddAzureOpenAIChatCompletion(deploymentName, endpoint, apiKey, httpClient:httpClient)\n",
    "    .AddAzureOpenAITextEmbeddingGeneration(adaDeploymentName, endpoint, apiKey, httpClient:httpClient)\n",
    "    .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable CS8618,IDE0009,CA1051,CA1050,CA1707,CA2007,VSTHRD111,CS1591,RCS1110,CA5394,SKEXP0001,SKEXP0002,SKEXP0003,SKEXP0004,SKEXP0010,SKEXP0011,SKEXP0012,SKEXP0020,SKEXP0021,SKEXP0022,SKEXP0023,SKEXP0024,SKEXP0025,SKEXP0026,SKEXP0027,SKEXP0028,SKEXP0029,SKEXP0030,SKEXP0031,SKEXP0032,SKEXP0040,SKEXP0041,SKEXP0042,SKEXP0050,SKEXP0051,SKEXP0052,SKEXP0053,SKEXP0054,SKEXP0055,SKEXP0060,SKEXP0061,SKEXP0101,SKEXP0102\n",
    "\n",
    "ConnectionMultiplexer connectionMultiplexer = await ConnectionMultiplexer.ConnectAsync(redis_conn_str);\n",
    "IDatabase database = connectionMultiplexer.GetDatabase();\n",
    "var memoryStore = new RedisMemoryStore(database, vectorSize: ADA_EMBEDDING_SIZE);\n",
    "\n",
    "// Reset the collection\n",
    "if (await memoryStore.DoesCollectionExistAsync(MemoryCollectionName))\n",
    "    await memoryStore.DeleteCollectionAsync(MemoryCollectionName);\n",
    "\n",
    "var embeddingGenerator = new AzureOpenAITextEmbeddingGenerationService(adaDeploymentName, endpoint, apiKey);\n",
    "\n",
    "// The combination of the text embedding generator and the memory store makes up the 'SemanticTextMemory' object used to\n",
    "// store and retrieve memories.\n",
    "SemanticTextMemory textMemory = new(memoryStore, embeddingGenerator);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read and save to and from Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "async Task<Chunk?> CheckInCache(string question, double minRelevance=0.8)\n",
    "{\n",
    "    try \n",
    "    {\n",
    "        Chunk? chunk = null;    \n",
    "        #pragma warning disable CS8618,IDE0009,CA1051,CA1050,CA1707,CA2007,VSTHRD111,CS1591,RCS1110,CA5394,SKEXP0001,SKEXP0002,SKEXP0003,SKEXP0004,SKEXP0010,SKEXP0011,SKEXP0012,SKEXP0020,SKEXP0021,SKEXP0022,SKEXP0023,SKEXP0024,SKEXP0025,SKEXP0026,SKEXP0027,SKEXP0028,SKEXP0029,SKEXP0030,SKEXP0031,SKEXP0032,SKEXP0040,SKEXP0041,SKEXP0042,SKEXP0050,SKEXP0051,SKEXP0052,SKEXP0053,SKEXP0054,SKEXP0055,SKEXP0060,SKEXP0061,SKEXP0101,SKEXP0102\n",
    "        IAsyncEnumerable<MemoryQueryResult> queryResults =\n",
    "                        textMemory.SearchAsync(MemoryCollectionName, question, limit: 1, minRelevanceScore: minRelevance);\n",
    "        await foreach (MemoryQueryResult r in queryResults)\n",
    "        {\n",
    "            chunk = new Chunk(r.Metadata.Id, r.Metadata.Text, string.Empty);\n",
    "        }\n",
    "        return chunk;\n",
    "    }\n",
    "    catch (Exception)\n",
    "    {\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\n",
    "async Task SaveInCache(Chunk chunk)\n",
    "{\n",
    "    await textMemory.SaveInformationAsync(MemoryCollectionName, id: chunk.Id, text: chunk.Text);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "async Task<string> CallLLM(string prompt, int maxTokens = 500, double temperature = 0.1)\n",
    "{\n",
    "    var skfunc = kernel.CreateFunctionFromPrompt(prompt, new AzureOpenAIPromptExecutionSettings{ MaxTokens = maxTokens, Temperature = temperature, TopP = 1 });\n",
    "    var result = await kernel.InvokeAsync(skfunc);\n",
    "    return result.ToString();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt the completion looking at the Cache results first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "async Task ProcessPrompt(string prompt)\n",
    "{\n",
    "    var chunk = await CheckInCache(prompt);\n",
    "    if (chunk is null)\n",
    "    {\n",
    "        // Handle Cache miss\n",
    "        Console.WriteLine($\"Cache miss:\\nuser: {prompt}\");\n",
    "        var result = await CallLLM(prompt);\n",
    "        Console.WriteLine($\"Calling the LLM\\nResult: {result}\");\n",
    "        chunk = new Chunk(Guid.NewGuid().ToString(), result, string.Empty);\n",
    "        Console.WriteLine($\"Adding the result to cache.\");\n",
    "        await SaveInCache(chunk);\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        // Handle Cache hit\n",
    "        Console.WriteLine($\"Cache hit:\");\n",
    "        Console.WriteLine($\"user: {prompt}\");\n",
    "        Console.WriteLine($\"assitant: {chunk.Text}\");\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the first Prompt and cache the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "await ProcessPrompt(\"What is the speed of light?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Prompt slightly and try to get the answer from cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "await ProcessPrompt(\"State the speed of light.\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
